{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69738200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_tuner\n",
      "  Downloading keras_tuner-1.0.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from keras_tuner) (7.22.0)\n",
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from keras_tuner) (20.9)\n",
      "Requirement already satisfied: scipy in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from keras_tuner) (1.6.2)\n",
      "Requirement already satisfied: requests in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from keras_tuner) (2.25.1)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt-legacy-1.0.3.tar.gz (5.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from keras_tuner) (1.20.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from ipython->keras_tuner) (0.17.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from ipython->keras_tuner) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from ipython->keras_tuner) (5.0.5)\n",
      "Requirement already satisfied: pygments in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from ipython->keras_tuner) (2.8.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from ipython->keras_tuner) (0.7.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from ipython->keras_tuner) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from ipython->keras_tuner) (52.0.0.post20210125)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from ipython->keras_tuner) (3.0.17)\n",
      "Requirement already satisfied: decorator in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from ipython->keras_tuner) (5.0.6)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->keras_tuner) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras_tuner) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->keras_tuner) (0.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from packaging->keras_tuner) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (4.0.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.32.1-py2.py3-none-any.whl (147 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Using cached protobuf-3.17.3-cp38-cp38-win_amd64.whl (909 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from tensorboard->keras_tuner) (0.36.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from tensorboard->keras_tuner) (1.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.38.1-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: six in c:\\users\\jairo\\anaconda3\\lib\\site-packages (from absl-py>=0.4->tensorboard->keras_tuner) (1.15.0)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: kt-legacy\n",
      "  Building wheel for kt-legacy (setup.py): started\n",
      "  Building wheel for kt-legacy (setup.py): finished with status 'done'\n",
      "  Created wheel for kt-legacy: filename=kt_legacy-1.0.3-py3-none-any.whl size=9562 sha256=41de59fa5f1ac739982b0fabde8345049e1efc119773100260bb1bd263325e1c\n",
      "  Stored in directory: c:\\users\\jairo\\appdata\\local\\pip\\cache\\wheels\\f2\\2e\\6b\\ce6f26f303aa955673b067602e7e388625406cc84db29f257b\n",
      "Successfully built kt-legacy\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard, kt-legacy, keras-tuner\n",
      "Successfully installed absl-py-0.13.0 cachetools-4.2.2 google-auth-1.32.1 google-auth-oauthlib-0.4.4 grpcio-1.38.1 keras-tuner-1.0.3 kt-legacy-1.0.3 markdown-3.3.4 oauthlib-3.1.1 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61169fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import time\n",
    "import keras_tuner\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization, CuDNNGRU, CuDNNLSTM\n",
    "import keras_tuner as kt\n",
    "import keras\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34dc24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/processed/train.csv')\n",
    "test = pd.read_csv('../Data/processed/test.csv')\n",
    "train['X'] = train['X'].apply(eval)\n",
    "train['y'] = train['y'].apply(eval)\n",
    "test['X'] = test['X'].apply(eval)\n",
    "test['y'] = test['y'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8491e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack(train['X'].values)\n",
    "y_train = np.vstack(train['y'].values)\n",
    "X_test = np.vstack(test['X'].values)\n",
    "y_test = np.vstack(test['y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6d6c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31888, 200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448213c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "emb = gensim.downloader.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb1aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = joblib.load('./Tokenizer/tok.joblib')\n",
    "word2idx = tokenizer.word_index\n",
    "max_vocab_size = 20000\n",
    "embedding_dim = 50\n",
    "num_words = min(max_vocab_size, len(word2idx) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c77f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95470b8-6381-4e6f-8367-44faf0c20401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI EMPIEZA EL HIPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6766aec5-b227-4a5b-bc13-db8afa517a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e12130a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVTuner(keras_tuner.engine.tuner.Tuner): \n",
    "\n",
    "    def __init__(self, data_cv, goal, hypermodel,oracle, proj_name, directory, overwrite):    \n",
    "                self.data_cv = data_cv  \n",
    "                self.goal = goal\n",
    "                self.trial_scores = []\n",
    "                keras_tuner.engine.tuner.Tuner.__init__(self, hypermodel=hypermodel, oracle=oracle, project_name = proj_name,\n",
    "                                                       directory=directory, overwrite=overwrite)\n",
    "\n",
    "\n",
    "    def run_trial(self, trial, x, y, batch_size=32, epochs=1):\n",
    "    \n",
    "        val_f1 = []\n",
    "        val_auc= []\n",
    "        val_acc = []\n",
    "\n",
    "        for train_indices, test_indices in self.data_cv.split(x, y):\n",
    "            \n",
    "            x_train, x_test = x[train_indices], x[test_indices]\n",
    "            y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "            model = self.hypermodel.build(trial.hyperparameters)  \n",
    "\n",
    "            callback=[keras.callbacks.EarlyStopping(monitor=self.goal, mode='max', patience=2)]\n",
    "\n",
    "            model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,callbacks = callback)\n",
    "            y_pred = model.predict(x_test)\n",
    "            f1 = model.evaluate(x_test, y_test)\n",
    "            auc = roc_auc_score(y_test,y_pred, average='weighted')\n",
    "            acc = accuracy_score(y_test,np.round(y_pred))\n",
    "            val_auc.append(auc)\n",
    "            val_f1.append(f1)\n",
    "            val_acc.append(acc)\n",
    "        \n",
    "        val_f1 = np.array(val_f1)[:,1]\n",
    "        val_auc = np.array(val_auc)\n",
    "        val_acc = np.array(val_acc)\n",
    "        self.trial_scores.append({'id':trial.trial_id,\n",
    "                                'hyperparams':trial.hyperparameters.values,\n",
    "                                'f1': np.mean(val_f1),\n",
    "                                'f1_std': np.std(val_f1),\n",
    "                                'Roc_auc': np.mean(val_auc),\n",
    "                                'Roc_auc_std': np.std(val_auc),\n",
    "                                'Accuracy': np.mean(val_acc),\n",
    "                                'Accuracy_std': np.std(val_acc)\n",
    "                                 })\n",
    "\n",
    "        self.oracle.update_trial(trial.trial_id, {self.goal: np.mean(val_f1)})\n",
    "        self.save_model(trial.trial_id, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "703c38c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./cv/cv.joblib']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = MultilabelStratifiedKFold(n_splits=5)\n",
    "joblib.dump(cv, './cv/cv.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "110242e8-3822-4e5d-a997-e331d2b406f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_Simple(hp):\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_matrix = np.empty((num_words,embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i>=max_vocab_size:\n",
    "          break\n",
    "        try:\n",
    "            embedding_matrix[i] = emb.get_vector(word)\n",
    "        except:\n",
    "            \n",
    "            continue;\n",
    "    model = ... ##Your code Here\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6ccda8d3-e692-4c6b-a94b-639fd75969fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 31m 46s]\n",
      "f1: 0.4813816905021667\n",
      "\n",
      "Best f1 So Far: 0.49923574924468994\n",
      "Total elapsed time: 02h 41m 20s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_Simple = CVTuner(\n",
    "                    data_cv= cv,\n",
    "                    goal = 'f1',\n",
    "                    hypermodel=build_model_Simple,\n",
    "                    oracle=keras_tuner.oracles.BayesianOptimizationOracle(\n",
    "                    objective=kt.Objective('f1',direction = \"max\"),\n",
    "                        max_trials=5                  \n",
    "                    ),\n",
    "                    directory='./experiments/',\n",
    "                    proj_name = 'simplernn',\n",
    "                    overwrite=False\n",
    "                    )\n",
    "tuner_Simple.search(X_train, y_train, 128, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef113a5c-901f-418e-8a07-028526c6fd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>Roc_auc</th>\n",
       "      <th>Roc_auc_std</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>727f341ff8e33a7cf5d073bb8bfd757e</td>\n",
       "      <td>{'input_units': 140, 'Dense_units': 30}</td>\n",
       "      <td>0.492363</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>0.942081</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.910718</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7590506718fe156b307c743da8d273dd</td>\n",
       "      <td>{'input_units': 200, 'Dense_units': 20}</td>\n",
       "      <td>0.451275</td>\n",
       "      <td>0.057606</td>\n",
       "      <td>0.935533</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>0.908476</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331298fd999c8056791fc2b3f818df63</td>\n",
       "      <td>{'input_units': 140, 'Dense_units': 10}</td>\n",
       "      <td>0.499236</td>\n",
       "      <td>0.038593</td>\n",
       "      <td>0.951144</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.910796</td>\n",
       "      <td>0.001939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ffab6e6fbedc2cc024f30fe7e0166ad</td>\n",
       "      <td>{'input_units': 180, 'Dense_units': 10}</td>\n",
       "      <td>0.451514</td>\n",
       "      <td>0.088417</td>\n",
       "      <td>0.946456</td>\n",
       "      <td>0.009838</td>\n",
       "      <td>0.909119</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f594af29e851d674eff5eb5d9e9718ec</td>\n",
       "      <td>{'input_units': 100, 'Dense_units': 50}</td>\n",
       "      <td>0.481382</td>\n",
       "      <td>0.035742</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.008538</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.001363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                              hyperparams  \\\n",
       "0  727f341ff8e33a7cf5d073bb8bfd757e  {'input_units': 140, 'Dense_units': 30}   \n",
       "1  7590506718fe156b307c743da8d273dd  {'input_units': 200, 'Dense_units': 20}   \n",
       "2  331298fd999c8056791fc2b3f818df63  {'input_units': 140, 'Dense_units': 10}   \n",
       "3  3ffab6e6fbedc2cc024f30fe7e0166ad  {'input_units': 180, 'Dense_units': 10}   \n",
       "4  f594af29e851d674eff5eb5d9e9718ec  {'input_units': 100, 'Dense_units': 50}   \n",
       "\n",
       "         f1    f1_std   Roc_auc  Roc_auc_std  Accuracy  Accuracy_std  \n",
       "0  0.492363  0.015880  0.942081     0.004595  0.910718      0.001818  \n",
       "1  0.451275  0.057606  0.935533     0.012771  0.908476      0.002270  \n",
       "2  0.499236  0.038593  0.951144     0.004175  0.910796      0.001939  \n",
       "3  0.451514  0.088417  0.946456     0.009838  0.909119      0.002118  \n",
       "4  0.481382  0.035742  0.947996     0.008538  0.909856      0.001363  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tuner_Simple.trial_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "912e6733-245c-4ad3-af9e-234b1d7bf1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 200, 50)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 140)               26740     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1410      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "=================================================================\n",
      "Total params: 1,028,216\n",
      "Trainable params: 28,216\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simpleModel = tuner_Simple.get_best_models()[0]\n",
    "simpleModel.save('models/simplernn_rnn.h5')\n",
    "simpleModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2378f0b1-7db2-439e-9ade-dca08bac9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_LSTM(hp):\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_matrix = np.empty((num_words,embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i>=max_vocab_size:\n",
    "          break\n",
    "        try:\n",
    "            embedding_matrix[i] = emb.get_vector(word)\n",
    "        except:\n",
    "            \n",
    "            continue;\n",
    "    model = ... # Your code Here \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "907353ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 05m 13s]\n",
      "f1: 0.5932714223861695\n",
      "\n",
      "Best f1 So Far: 0.6134765386581421\n",
      "Total elapsed time: 00h 27m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_LSTM = CVTuner(\n",
    "                    data_cv= cv,\n",
    "                    goal = 'f1',\n",
    "                    hypermodel=build_model_LSTM,\n",
    "                    oracle=keras_tuner.oracles.BayesianOptimizationOracle(\n",
    "                    objective=kt.Objective('f1',direction = \"max\"),\n",
    "                        max_trials=5                 \n",
    "                    ),\n",
    "                    directory='./experiments/',\n",
    "                    proj_name = 'lstm',\n",
    "                    overwrite=False\n",
    "                    )\n",
    "tuner_LSTM.search(X_train, y_train, 128, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "212e2c00-459d-4858-bfe9-04280138b9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>Roc_auc</th>\n",
       "      <th>Roc_auc_std</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26e417b2d1cfd3e6b7b055f7658fbf4c</td>\n",
       "      <td>{'input_units': 160, 'Dense_units': 40}</td>\n",
       "      <td>0.592694</td>\n",
       "      <td>0.015204</td>\n",
       "      <td>0.972949</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.917006</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b84f4e3ed4766fef517e1e241876ec7e</td>\n",
       "      <td>{'input_units': 140, 'Dense_units': 30}</td>\n",
       "      <td>0.613477</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.973347</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.915947</td>\n",
       "      <td>0.000888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d74d49ba167ccf17932547f2f0075730</td>\n",
       "      <td>{'input_units': 200, 'Dense_units': 30}</td>\n",
       "      <td>0.592609</td>\n",
       "      <td>0.024769</td>\n",
       "      <td>0.973072</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.916982</td>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20a32db5b8bb7031884b0e48a54ad526</td>\n",
       "      <td>{'input_units': 180, 'Dense_units': 30}</td>\n",
       "      <td>0.593942</td>\n",
       "      <td>0.017847</td>\n",
       "      <td>0.973918</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.917280</td>\n",
       "      <td>0.001661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ee86cf40d52f9274f2d0704b35c6828</td>\n",
       "      <td>{'input_units': 100, 'Dense_units': 20}</td>\n",
       "      <td>0.593271</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.972290</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.917053</td>\n",
       "      <td>0.001234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                              hyperparams  \\\n",
       "0  26e417b2d1cfd3e6b7b055f7658fbf4c  {'input_units': 160, 'Dense_units': 40}   \n",
       "1  b84f4e3ed4766fef517e1e241876ec7e  {'input_units': 140, 'Dense_units': 30}   \n",
       "2  d74d49ba167ccf17932547f2f0075730  {'input_units': 200, 'Dense_units': 30}   \n",
       "3  20a32db5b8bb7031884b0e48a54ad526  {'input_units': 180, 'Dense_units': 30}   \n",
       "4  6ee86cf40d52f9274f2d0704b35c6828  {'input_units': 100, 'Dense_units': 20}   \n",
       "\n",
       "         f1    f1_std   Roc_auc  Roc_auc_std  Accuracy  Accuracy_std  \n",
       "0  0.592694  0.015204  0.972949     0.001232  0.917006      0.001276  \n",
       "1  0.613477  0.007131  0.973347     0.001586  0.915947      0.000888  \n",
       "2  0.592609  0.024769  0.973072     0.001707  0.916982      0.001386  \n",
       "3  0.593942  0.017847  0.973918     0.000998  0.917280      0.001661  \n",
       "4  0.593271  0.020700  0.972290     0.001695  0.917053      0.001234  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tuner_LSTM.trial_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "76daa3f8-8451-40f0-b6ec-d6c537bb8f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 200, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 140)               106960    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                4230      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 186       \n",
      "=================================================================\n",
      "Total params: 1,111,376\n",
      "Trainable params: 111,376\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstmModel = tuner_LSTM.get_best_models()[0]\n",
    "lstmModel.save('models/lstm_rnn.h5')\n",
    "lstmModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b04c810-2d5a-429f-ba6c-77b10fe21e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_bidirectional_simple(hp):\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_matrix = np.empty((num_words,embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i>=max_vocab_size:\n",
    "          break\n",
    "        try:\n",
    "            embedding_matrix[i] = emb.get_vector(word)\n",
    "        except:\n",
    "            \n",
    "            continue;\n",
    "    model = .... #Your code here\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5ce4e9cd-ab44-4d5c-9657-f9844cf2da24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [01h 46m 38s]\n",
      "f1: 0.5815940976142884\n",
      "\n",
      "Best f1 So Far: 0.6118112802505493\n",
      "Total elapsed time: 12h 24m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_simple_bidir = CVTuner(\n",
    "                    data_cv= cv,\n",
    "                    goal = 'f1',\n",
    "                    hypermodel=build_model_GRU,\n",
    "                    oracle=keras_tuner.oracles.BayesianOptimizationOracle(\n",
    "                    objective=kt.Objective('f1',direction = \"max\"),\n",
    "                        max_trials=5                 \n",
    "                    ),\n",
    "                    directory='./experiments/',\n",
    "                    proj_name = 'bidirectional_simplernn',\n",
    "                    overwrite=False\n",
    "                    )\n",
    "tuner_simple_bidir.search(X_train, y_train, 128, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4a51024a-413e-4648-803e-d82d6280b717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>Roc_auc</th>\n",
       "      <th>Roc_auc_std</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b7e7f841a4479c772ac057a4edc37513</td>\n",
       "      <td>{'input_units': 180, 'Dense_units': 20}</td>\n",
       "      <td>0.609482</td>\n",
       "      <td>0.026291</td>\n",
       "      <td>0.974023</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.916355</td>\n",
       "      <td>0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9b10ae046fa5bdd416c376bf66e6baa</td>\n",
       "      <td>{'input_units': 200, 'Dense_units': 10}</td>\n",
       "      <td>0.580826</td>\n",
       "      <td>0.016576</td>\n",
       "      <td>0.972954</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.917359</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dcb2185e2b12300c2e45ca03bd12aa6c</td>\n",
       "      <td>{'input_units': 140, 'Dense_units': 20}</td>\n",
       "      <td>0.599561</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>0.974160</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.917288</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>962f210370db6c8cc839a5c3953e2926</td>\n",
       "      <td>{'input_units': 120, 'Dense_units': 40}</td>\n",
       "      <td>0.611811</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.975010</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.917335</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be35d96551ff7cb44a687a4917ee0925</td>\n",
       "      <td>{'input_units': 100, 'Dense_units': 10}</td>\n",
       "      <td>0.581594</td>\n",
       "      <td>0.030801</td>\n",
       "      <td>0.972989</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.915869</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                              hyperparams  \\\n",
       "0  b7e7f841a4479c772ac057a4edc37513  {'input_units': 180, 'Dense_units': 20}   \n",
       "1  d9b10ae046fa5bdd416c376bf66e6baa  {'input_units': 200, 'Dense_units': 10}   \n",
       "2  dcb2185e2b12300c2e45ca03bd12aa6c  {'input_units': 140, 'Dense_units': 20}   \n",
       "3  962f210370db6c8cc839a5c3953e2926  {'input_units': 120, 'Dense_units': 40}   \n",
       "4  be35d96551ff7cb44a687a4917ee0925  {'input_units': 100, 'Dense_units': 10}   \n",
       "\n",
       "         f1    f1_std   Roc_auc  Roc_auc_std  Accuracy  Accuracy_std  \n",
       "0  0.609482  0.026291  0.974023     0.001036  0.916355      0.001487  \n",
       "1  0.580826  0.016576  0.972954     0.001082  0.917359      0.000706  \n",
       "2  0.599561  0.014252  0.974160     0.001873  0.917288      0.001122  \n",
       "3  0.611811  0.020767  0.975010     0.000752  0.917335      0.001200  \n",
       "4  0.581594  0.030801  0.972989     0.001457  0.915869      0.001170  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tuner_simple_bidir.trial_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bb0cdb3e-c19e-4f2b-a6bb-ed5c95bcab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 50)          1000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 120)               61920     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                4840      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 246       \n",
      "=================================================================\n",
      "Total params: 1,067,006\n",
      "Trainable params: 67,006\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_bidir_Model = tuner_simple_bidir.get_best_models()[0]\n",
    "simple_bidir_Model.save('models/bidirectional_simplernn.h5')\n",
    "simple_bidir_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "26854ba6-ed93-445a-99ea-28f45979efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_bidirectional_lstm(hp):\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_matrix = np.empty((num_words,embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i>=max_vocab_size:\n",
    "          break\n",
    "        try:\n",
    "            embedding_matrix[i] = emb.get_vector(word)\n",
    "        except:\n",
    "            \n",
    "            continue;\n",
    "    model = ... #Your code here\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "24f0f07b-4750-45c0-978e-456fd3237b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 09m 24s]\n",
      "f1: 0.5817522764205932\n",
      "\n",
      "Best f1 So Far: 0.6067933559417724\n",
      "Total elapsed time: 00h 45m 13s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_lstm_bidir = CVTuner(\n",
    "                    data_cv= cv,\n",
    "                    goal = 'f1',\n",
    "                    hypermodel=build_model_bidirectional_lstm,\n",
    "                    oracle=keras_tuner.oracles.BayesianOptimizationOracle(\n",
    "                    objective=kt.Objective('f1',direction = \"max\"),\n",
    "                        max_trials=5                 \n",
    "                    ),\n",
    "                    directory='./experiments/',\n",
    "                    proj_name = 'bidirectional_lstm',\n",
    "                    overwrite=False\n",
    "                    )\n",
    "tuner_lstm_bidir.search(X_train, y_train, 128, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ec0568f4-d422-436e-8852-5284ac5ded6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>Roc_auc</th>\n",
       "      <th>Roc_auc_std</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6800a8de5aa2cf31ad515ff5ab81ca79</td>\n",
       "      <td>{'input_units': 120, 'Dense_units': 50}</td>\n",
       "      <td>0.601179</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.974038</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.916371</td>\n",
       "      <td>0.001741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e71a33757ab0786baa314e9efb4a75b7</td>\n",
       "      <td>{'input_units': 140, 'Dense_units': 40}</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.029606</td>\n",
       "      <td>0.973162</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.913972</td>\n",
       "      <td>0.003264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82cde8b0c944ed575520d173d24f09aa</td>\n",
       "      <td>{'input_units': 180, 'Dense_units': 40}</td>\n",
       "      <td>0.504029</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.957147</td>\n",
       "      <td>0.033498</td>\n",
       "      <td>0.912890</td>\n",
       "      <td>0.007319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220f74f1d48f542743bdef9541215f8e</td>\n",
       "      <td>{'input_units': 200, 'Dense_units': 10}</td>\n",
       "      <td>0.572545</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>0.971102</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.915187</td>\n",
       "      <td>0.001287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ae27e52c0b19ec62d1731a789ac0f53</td>\n",
       "      <td>{'input_units': 160, 'Dense_units': 20}</td>\n",
       "      <td>0.581752</td>\n",
       "      <td>0.029449</td>\n",
       "      <td>0.973074</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.916771</td>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                              hyperparams  \\\n",
       "0  6800a8de5aa2cf31ad515ff5ab81ca79  {'input_units': 120, 'Dense_units': 50}   \n",
       "1  e71a33757ab0786baa314e9efb4a75b7  {'input_units': 140, 'Dense_units': 40}   \n",
       "2  82cde8b0c944ed575520d173d24f09aa  {'input_units': 180, 'Dense_units': 40}   \n",
       "3  220f74f1d48f542743bdef9541215f8e  {'input_units': 200, 'Dense_units': 10}   \n",
       "4  7ae27e52c0b19ec62d1731a789ac0f53  {'input_units': 160, 'Dense_units': 20}   \n",
       "\n",
       "         f1    f1_std   Roc_auc  Roc_auc_std  Accuracy  Accuracy_std  \n",
       "0  0.601179  0.025023  0.974038     0.001790  0.916371      0.001741  \n",
       "1  0.606793  0.029606  0.973162     0.000641  0.913972      0.003264  \n",
       "2  0.504029  0.227724  0.957147     0.033498  0.912890      0.007319  \n",
       "3  0.572545  0.048869  0.971102     0.001333  0.915187      0.001287  \n",
       "4  0.581752  0.029449  0.973074     0.000954  0.916771      0.000912  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tuner_lstm_bidir.trial_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c61c95cb-8e5d-4e2a-826f-05cc1f15b917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 200, 50)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 280)               213920    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                11240     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 246       \n",
      "=================================================================\n",
      "Total params: 1,225,406\n",
      "Trainable params: 225,406\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_bidir_Model = tuner_lstm_bidir.get_best_models()[0]\n",
    "lstm_bidir_Model.save('models/bidirectional_lstm.h5')\n",
    "lstm_bidir_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56008810-a872-4916-98ce-f04a6a238514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_best_model():\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_matrix = np.empty((num_words,embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i>=max_vocab_size:\n",
    "          break\n",
    "        try:\n",
    "            embedding_matrix[i] = emb.get_vector(word)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    model = ... #Your code here\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ee1b8d1-4866-4202-b1ea-fae106d3446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataValidation(keras.callbacks.Callback):\n",
    "    def __init__(self, x=None, y=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def f1(self, y_true, y_pred):\n",
    "        def recall(y_true, y_pred):\n",
    "            \"\"\"Recall metric.\n",
    "\n",
    "            Only computes a batch-wise average of recall.\n",
    "\n",
    "            Computes the recall, a metric for multi-label classification of\n",
    "            how many relevant items are selected.\n",
    "            \"\"\"\n",
    "            true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "            possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "            recall = true_positives / (possible_positives + K.epsilon())\n",
    "            return recall\n",
    "\n",
    "        def precision(y_true, y_pred):\n",
    "            \"\"\"Precision metric.\n",
    "\n",
    "            Only computes a batch-wise average of precision.\n",
    "\n",
    "            Computes the precision, a metric for multi-label classification of\n",
    "            how many selected items are relevant.\n",
    "            \"\"\"\n",
    "            true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "            predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "            precision = true_positives / (predicted_positives + K.epsilon())\n",
    "            return precision\n",
    "        precision = precision(y_true, y_pred)\n",
    "        recall = recall(y_true, y_pred)\n",
    "        return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.round(self.model.predict(self.x))\n",
    "        self.y = tf.convert_to_tensor(self.y, dtype=tf.float64)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float64)\n",
    "        f1_s = self.f1(self.y, y_pred)\n",
    "        logs[\"f1_val_cust\"] = f1_s\n",
    "        print(f'f1_val_cust:{f1_s}')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "153e6365-9ab3-478e-9475-7b2568e6529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "997/997 [==============================] - 24s 23ms/step - loss: 0.0840 - f1: 0.5320\n",
      "f1_val_cust:0.6590282085582988\n",
      "Epoch 2/100\n",
      "997/997 [==============================] - 22s 22ms/step - loss: 0.0624 - f1: 0.6401\n",
      "f1_val_cust:0.7025259054651847\n",
      "Epoch 3/100\n",
      "997/997 [==============================] - 20s 21ms/step - loss: 0.0599 - f1: 0.6553\n",
      "f1_val_cust:0.709376957862062\n",
      "Epoch 4/100\n",
      "997/997 [==============================] - 22s 22ms/step - loss: 0.0569 - f1: 0.6690\n",
      "f1_val_cust:0.7039316592679934\n",
      "Epoch 5/100\n",
      "997/997 [==============================] - 22s 22ms/step - loss: 0.0555 - f1: 0.6745\n",
      "f1_val_cust:0.7138614164008681\n",
      "Epoch 6/100\n",
      "997/997 [==============================] - 19s 19ms/step - loss: 0.0539 - f1: 0.6857\n",
      "f1_val_cust:0.7187752627715868\n",
      "Epoch 7/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0525 - f1: 0.6918\n",
      "f1_val_cust:0.7231852589282541\n",
      "Epoch 8/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0514 - f1: 0.6977\n",
      "f1_val_cust:0.7185238882360611\n",
      "Epoch 9/100\n",
      "997/997 [==============================] - 19s 19ms/step - loss: 0.0504 - f1: 0.7020\n",
      "f1_val_cust:0.7257793941283395\n",
      "Epoch 10/100\n",
      "997/997 [==============================] - 22s 22ms/step - loss: 0.0497 - f1: 0.7108\n",
      "f1_val_cust:0.7224123389667532\n",
      "Epoch 11/100\n",
      "997/997 [==============================] - 22s 23ms/step - loss: 0.0485 - f1: 0.7117\n",
      "f1_val_cust:0.723677737820555\n",
      "Epoch 12/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0482 - f1: 0.7153\n",
      "f1_val_cust:0.723992148642885\n",
      "Epoch 13/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0473 - f1: 0.7193\n",
      "f1_val_cust:0.7361828219372408\n",
      "Epoch 14/100\n",
      "997/997 [==============================] - 20s 21ms/step - loss: 0.0465 - f1: 0.7233\n",
      "f1_val_cust:0.7345948832172295\n",
      "Epoch 15/100\n",
      "997/997 [==============================] - 21s 21ms/step - loss: 0.0457 - f1: 0.7292\n",
      "f1_val_cust:0.7343193368204791\n",
      "Epoch 16/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0454 - f1: 0.7296\n",
      "f1_val_cust:0.7389708257544805\n",
      "Epoch 17/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0448 - f1: 0.7350\n",
      "f1_val_cust:0.7395477979980546\n",
      "Epoch 18/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0438 - f1: 0.7388\n",
      "f1_val_cust:0.7458339089990795\n",
      "Epoch 19/100\n",
      "997/997 [==============================] - 20s 21ms/step - loss: 0.0434 - f1: 0.7430\n",
      "f1_val_cust:0.7420695530268029\n",
      "Epoch 20/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0429 - f1: 0.7407\n",
      "f1_val_cust:0.7404469031800198\n",
      "Epoch 21/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0422 - f1: 0.7460\n",
      "f1_val_cust:0.7396040626081337\n",
      "Epoch 22/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0420 - f1: 0.7478\n",
      "f1_val_cust:0.735505279377795\n",
      "Epoch 23/100\n",
      "997/997 [==============================] - 20s 20ms/step - loss: 0.0412 - f1: 0.7541\n",
      "f1_val_cust:0.7405670579291628\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "f_model = build_lstm_best_model()\n",
    "es = EarlyStopping(monitor='f1_val_cust', mode='max', patience=5, verbose=1)\n",
    "history = f_model.fit(X_train, y_train, batch_size=128, epochs=100, callbacks=[CustomDataValidation(X_test, y_test), es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79391845-ab87-42f4-b793-3255bf542e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7320506351650181"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = f_model.predict(X_test)\n",
    "f1_score(y_test, np.round(y_pred), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ebf42130-9f13-4e75-8d6b-ba11a57b0e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.799, Test: 0.732\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = f1_score(y_train, np.round(f_model.predict(X_train)), average='weighted')\n",
    "test_acc = f1_score(y_test, np.round(f_model.predict(X_test)), average='weighted')\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot training history\n",
    "plt.plot(history.history['f1'], label='train')\n",
    "plt.plot(history.history['f1_val_cust'], label='test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "03821f55-5e7f-4bca-9ceb-73654fcf0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model.save('models/lstm_final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f2dfb-1693-4413-99fb-ff0522df551e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
